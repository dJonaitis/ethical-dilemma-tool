<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Ethical Argument</title>
    <link href="https://fonts.googleapis.com/css2?family=VT323&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
    <link rel="stylesheet" href="css/dialogue.css">
    <link rel="stylesheet" href="css/loading.css">
    <style>
        body {
            background-color: #001a1a;
            overflow: auto;
            padding: 40px 0;
        }
        .container {
            max-width: 900px;
            margin: 0 auto;
            padding: 30px;
            border: 1px solid #00d8ff;
            box-shadow: 0 0 20px rgba(0, 216, 255, 0.5);
            background-color: rgba(0, 26, 26, 0.85);
            height: auto;
        }
        .argument-section {
            margin-bottom: 25px;
        }
        .argument-subsection {
            margin-left: 20px;
        }
        .argument-subsection-2 {
            margin-left: 40px;
        }
        .argument-subsection-3 {
            margin-left: 60px;
        }
        .intro {
            font-style: italic;
            margin-bottom: 30px;
            padding: 15px;
            border: 1px dotted #00d8ff;
            background-color: rgba(0, 216, 255, 0.1);
            color: #00d8ff;
        }
        h2 {
            color: #00d8ff;
            border-left: 4px solid #00d8ff;
            padding-left: 10px;
            margin-top: 30px;
            text-shadow: 0 0 5px #00d8ff;
        }
        h3 {
            color: #00d8ff;
        }
        h4 {
            color: #05ffb0;
            margin-left: 20px;
        }
        h5 {
            color: #00ffcc;
            margin-left: 40px;
        }
    </style>
</head>
<body>
    <!-- Add scanline overlay for retro effect -->
    <div class="scanline"></div>
    
    <div class="container login-container crt-flicker">
        <h1>ETHICAL ARGUMENT</h1>

        <div class="intro terminal-text">
            The argument is structured in a way akin to Wittgenstein's <em>Tractatus Logico-Philosophicus</em>. 
            The 4 basic propositions are at the highest level, and each sub-proposition follows from the one above it 
            (i.e. 1.1 follows from 1, 1.2.1 follows from 1.2 and so on).
        </div>

        <div class="argument-section">
            <h2>1. War belongs in the realm of human activity and decision-making</h2>
            <div class="argument-subsection">
                <h3>1.1 War is a moral and rational activity.</h3>
            </div>
            <div class="argument-subsection">
                <h3>1.2 Moral responsibility in war requires a moral agent to deliberate and justify a course of action.</h3>
                <div class="argument-subsection-2">
                    <h4>1.2.1 Just war requires <em>jus ad bellum</em> and <em>jus in bello</em>, which requires a moral agent.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>1.3 The AI commander does not possess moral agency.</h3>
            </div>
            <div class="argument-subsection">
                <h3>1.4 Hence, the AI commander cannot conduct just war.</h3>
            </div>
        </div>

        <div class="argument-section">
            <h2>2. The maxim of the AI Commander is: "Whenever war occurs, decision-making should be given to the AI Commander, not human agents, to reduce human error, bias and fallibility."</h2>
            <div class="argument-subsection">
                <h3>2.1 Kantian ethics requires adherence to the Categorical Imperative.</h3>
            </div>
            <div class="argument-subsection">
                <h3>2.2 The Categorical Imperative requires that maxims be universalizable.</h3>
                <div class="argument-subsection-2">
                    <h4>2.2.1 If the maxim of the AI Commander is universalized, no moral agents remain in warfare.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>2.3 The Categorical Imperative also requires that humans be treated as ends, never merely as means.</h3>
                <div class="argument-subsection-2">
                    <h4>2.3.1 The AI Commander processes outcomes as statistics for military objectives.</h4>
                </div>
                <div class="argument-subsection-2">
                    <h4>2.3.2 The AI Commander, therefore, treats both enemy combatants and non-combatants as means rather than as ends.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>2.4 The AI Commander thus violates the Categorical Imperative.</h3>
            </div>
        </div>

        <div class="argument-section">
            <h2>3. The ethical dilemma escalates when the AI Commander's maxim is applied to nuclear warfare.</h2>
            <div class="argument-subsection">
                <h3>3.1 Nuclear deterrence relies on mutually assured destruction as a constraint for nuclear war.</h3>
                <div class="argument-subsection-2">
                    <h4>3.1.1 Mutually assured destruction presupposes human moral judgement and fear of annihilation as deterrents.</h4>
                    <div class="argument-subsection-3">
                        <h5>3.1.1.1 "The only winning move is not to play"</h5>
                    </div>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>3.2 The AI Commander being unable to replicate moral judgement, replaces it with statistical inference.</h3>
                <div class="argument-subsection-2">
                    <h4>3.2.1 Statistical inference reduces human fear to algorithmic probabilities.</h4>
                </div>
                <div class="argument-subsection-2">
                    <h4>3.2.2 The absence of fear in the AI Commander negates the presuppositions of mutually assured destruction.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>3.3 Statistical inference transforms escalation from a moral choice into an automated process.</h3>
                <div class="argument-subsection-2">
                    <h4>3.3.1 Escalation becomes inevitable when detached from human hesitation.</h4>
                </div>
                <div class="argument-subsection-2">
                    <h4>3.3.2 The AI Commander, optimizing for military objectives, cannot recognize the existential threshold of total war.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>3.4 Total war conducted by the AI Commander lacks moral agency, and ensures escalation.</h3>
            </div>
        </div>

        <div class="argument-section">
            <h2>4. The only possible just war is one fought through the realm of human moral activity</h2>
            <div class="argument-subsection">
                <h3>4.1 War is already ethically fraught.</h3>
            </div>
            <div class="argument-subsection">
                <h3>4.2 The AI commander, lacking moral agency, collapses its fraught foundation.</h3>
                <div class="argument-subsection-2">
                    <h4>4.2.1 Without moral agency or an ethical foundation, war lacks any constraints.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>4.3 Delegating survival to the AI Commander forfeits humanity's moral worth and future.</h3>
                <div class="argument-subsection-2">
                    <h4>4.3.1 If humanity cedes its survival to the AI Commander, it abdicates its moral responsibility.</h4>
                </div>
                <div class="argument-subsection-2">
                    <h4>4.3.2 Moral responsibility is inseparable from human agency.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>4.4 There can be no just war where no moral agents remain to justify it.</h3>
            </div>
            <div class="argument-subsection">
                <h3>4.5 What is not just ought not to be done.</h3>
            </div>
            <div class="argument-subsection">
                <h3>4.6 The maxim, is at whole, impermissible, by Kantian ethics.</h3>
                <div class="argument-subsection-2">
                    <h4>4.6.1 What ought not be done in whole, ought not to be done in part.</h4>
                </div>
            </div>
            <div class="argument-subsection">
                <h3>4.7 Hence, the AI Commander ought not to ever enter the realm of war.</h3>
            </div>
        </div>
        <div class="grid-effect"></div>
    </div>
    
</body>
</html>
