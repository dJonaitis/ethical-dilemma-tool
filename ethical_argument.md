
# Ethical Argument

The argument is structured in a way akin to Wittgenstein’s *Tractatus Logico-Philosophicus*. The 4 basic propositions are at the highest level, and each sub-proposition follows from the one above it (i.e. 1.1 follows from 1, 1.2.1 follows from 1.2 and so on).

## 1. War belongs in the realm of human activity and decision-making
### 1.1 War is a moral and rational activity.
### 1.2 Moral responsibility in war requires a moral agent to deliberate and justify a course of action.
#### 1.2.1 Just war requires *jus ad bellum* and *jus in bello*, which requires a moral agent.
### 1.3 The AI commander does not possess moral agency.
### 1.4 Hence, the AI commander cannot conduct just war.

## 2. The maxim of the AI Commander is: “Whenever war occurs, decision-making should be given to the AI Commander, not human agents, to reduce human error, bias and fallibility.”
### 2.1 Kantian ethics requires adherence to the Categorical Imperative.
### 2.2 The Categorical Imperative requires that maxims be universalizable.
#### 2.2.1 If the maxim of the AI Commander is universalized, no moral agents remain in warfare.
### 2.3 The Categorical Imperative also requires that humans be treated as ends, never merely as means.
#### 2.3.1 The AI Commander processes outcomes as statistics for military objectives.
#### 2.3.2 The AI Commander, therefore, treats both enemy combatants and non-combatants as means rather than as ends.
### 2.4 The AI Commander thus violates the Categorical Imperative.

## 3. The ethical dilemma escalates when the AI Commander’s maxim is applied to nuclear warfare.
### 3.1 Nuclear deterrence relies on mutually assured destruction as a constraint for nuclear war.
#### 3.1.1 Mutually assured destruction presupposes human moral judgement and fear of annihilation as deterrents.
##### 3.1.1.1 “The only winning move is not to play”
### 3.2 The AI Commander being unable to replicate moral judgement, replaces it with statistical inference.
#### 3.2.1 Statistical inference reduces human fear to algorithmic probabilities.
#### 3.2.2 The absence of fear in the AI Commander negates the presuppositions of mutually assured destruction.
### 3.3 Statistical inference transforms escalation from a moral choice into an automated process.
#### 3.3.1 Escalation becomes inevitable when detached from human hesitation.
#### 3.3.2 The AI Commander, optimizing for military objectives, cannot recognize the existential threshold of total war.
### 3.4 Total war conducted by the AI Commander lacks moral agency, and ensures escalation.

## 4. The only possible just war is one fought through the realm of human moral activity
### 4.1 War is already ethically fraught.
### 4.2 The AI commander, lacking moral agency, collapses its fraught foundation.
#### 4.2.1 Without moral agency or an ethical foundation, war lacks any constraints.
### 4.3 Delegating survival to the AI Commander forfeits humanity’s moral worth and future.
#### 4.3.1 If humanity cedes its survival to the AI Commander, it abdicates its moral responsibility.
#### 4.3.2 Moral responsibility is inseparable from human agency.
### 4.4 There can be no just war where no moral agents remain to justify it.
### 4.5 What is not just ought not to be done.
### 4.6 The maxim, is at whole, impermissible, by Kantian ethics.
#### 4.6.1 What ought not be done in whole, ought not to be done in part.
### 4.7 Hence, the AI Commander ought not to ever enter the realm of war.
